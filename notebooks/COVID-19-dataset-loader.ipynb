{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import done\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "import re\n",
    "import errno\n",
    "import json\n",
    "import pickle\n",
    "import glob\n",
    "import multiprocessing\n",
    "from time import time  # To time our operations\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "print('import done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "def clean(txt):\n",
    "    \"\"\"\n",
    "    Basic string loading code.\n",
    "\n",
    "    :param txt:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    txt = re.sub(r'.\\n+', '. ', txt)  # replace multiple newlines with period\n",
    "    txt = re.sub(r'\\n+', '', txt)  # replace multiple newlines with period\n",
    "    txt = re.sub(r'\\[\\d+\\]', ' ', txt)  # remove reference numbers\n",
    "    txt = re.sub(' +', ' ', txt)\n",
    "    \n",
    "    txt = re.sub(',', ' ', txt)\n",
    "    txt = re.sub(r'\\([^()]*\\)', '', txt)\n",
    "    txt = re.sub(r'https?:\\S+\\sdoi', '', txt)\n",
    "    txt = re.sub(r'biorxiv', '', txt)\n",
    "    txt = re.sub(r'preprint', '', txt)\n",
    "    txt = re.sub(r':', ' ', txt)\n",
    "    return txt.lower()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class document():\n",
    "    def __init__(self, file_path):\n",
    "        if file_path:\n",
    "            with open(file_path) as file:\n",
    "                data = json.load(file)\n",
    "                self.paper_id = data['paper_id']\n",
    "                self.title = data['metadata']['title']\n",
    "                self.abstract_tripples = {}\n",
    "                self.text_tripples = {}\n",
    "                self.key_phrases = \"\"\n",
    "                self.abstract = \"\"\n",
    "                self.text = \"\"\n",
    "                self.entities = {}\n",
    "                if 'abstract' in data:\n",
    "                    for section in data['abstract']:\n",
    "                        self.abstract = self.abstract + \"\\n\" + section[\"text\"]\n",
    "\n",
    "                for section in data['body_text']:\n",
    "                    self.text = self.text + \"\\n\" + section['text']\n",
    "\n",
    "    def clean_text(self):\n",
    "        self.abstract = clean(self.abstract)\n",
    "        self.text = clean(self.text)\n",
    "        self.title =clean(self.title)\n",
    "        final_data_dict = self.combine_data()\n",
    "        return final_data_dict\n",
    "\n",
    "    def combine_data(self):\n",
    "        self.data = {'paper_id': self.paper_id,\n",
    "                     'title': self.title,\n",
    "                     'abstract': self.abstract,\n",
    "                     'text': self.text,\n",
    "                     'abstract_tripples': self.abstract_tripples,\n",
    "                     'text_tripples': self.text_tripples,\n",
    "                     'key_phrases': self.key_phrases,\n",
    "                     'entities': self.entities}\n",
    "        return self.data\n",
    "\n",
    "    def extract_data(self):\n",
    "\n",
    "        self.paper_id = self.data['paper_id']\n",
    "        self.title = self.data['title']\n",
    "        self.abstract = self.data['abstract']\n",
    "        self.text = self.data['text']\n",
    "        self.abstract_tripples = self.data['abstract_tripples']\n",
    "        self.text_tripples = self.data['text_tripples']\n",
    "        self.key_phrases = self.data['key_phrases']\n",
    "        self.entities = self.data['entities']\n",
    "\n",
    "    def save(self, dir):\n",
    "        self.combine_data()\n",
    "\n",
    "        if not os.path.exists(os.path.dirname(dir)):\n",
    "            try:\n",
    "                os.makedirs(os.path.dirname(dir))\n",
    "            except OSError as exc:  # Guard against race condition\n",
    "                if exc.errno != errno.EEXIST:\n",
    "                    raise\n",
    "\n",
    "        with open(dir, 'w') as json_file:\n",
    "            json_file.write(json.dumps(self.data))\n",
    "\n",
    "    def load_saved_data(self, dir):\n",
    "        with open(dir) as json_file:\n",
    "            self.data = json.load(json_file)\n",
    "        self.extract_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############## Directory Working on #################\n",
      "/kaggle/input/CORD-19-research-challenge/noncomm_use_subset/noncomm_use_subset\n",
      "noncomm_use_subset\n",
      "4678\n",
      "Now writing back data\n",
      "files processed===>4678\n",
      "############## Directory Working on #################\n",
      "/kaggle/input/CORD-19-research-challenge/biorxiv_medrxiv/biorxiv_medrxiv\n",
      "biorxiv_medrxiv\n",
      "1934\n",
      "Now writing back data\n",
      "files processed===>1934\n",
      "############## Directory Working on #################\n",
      "/kaggle/input/CORD-19-research-challenge/comm_use_subset/comm_use_subset\n",
      "comm_use_subset\n",
      "18746\n",
      "Now writing back data\n",
      "files processed===>18746\n",
      "############## Directory Working on #################\n",
      "/kaggle/input/CORD-19-research-challenge/custom_license/custom_license\n",
      "custom_license\n",
      "35238\n",
      "Now writing back data\n",
      "files processed===>35238\n"
     ]
    }
   ],
   "source": [
    "desired_dirs=['/kaggle/input/CORD-19-research-challenge/noncomm_use_subset/noncomm_use_subset',\n",
    "             '/kaggle/input/CORD-19-research-challenge/biorxiv_medrxiv/biorxiv_medrxiv',\n",
    "             '/kaggle/input/CORD-19-research-challenge/comm_use_subset/comm_use_subset',\n",
    "             '/kaggle/input/CORD-19-research-challenge/custom_license/custom_license']\n",
    "\n",
    "\n",
    "noncomm_use_subset=[]\n",
    "biorxiv_medrxiv = []\n",
    "comm_use_subset = []\n",
    "custom_license = []\n",
    "\n",
    "for individual_dirs in desired_dirs:\n",
    "    files_list = []\n",
    "    data = []\n",
    "    print('############## Directory Working on #################')\n",
    "    print(individual_dirs)\n",
    "    print(individual_dirs.split('/')[-1])\n",
    "    for dirname,_, filenames in os.walk(individual_dirs):\n",
    "        #print(dirname)\n",
    "        for filename in filenames:\n",
    "            #print(os.path.join(dirname, filename))\n",
    "            files_list.append(os.path.join(dirname, filename))\n",
    "    print(len(files_list))\n",
    "    #print(files_list)\n",
    "    i=0\n",
    "    for individual_file in files_list:\n",
    "        try:\n",
    "            pub = document(individual_file)\n",
    "            data_dict = pub.clean_text()\n",
    "            #print(data_dict)\n",
    "            data.append(data_dict)\n",
    "            i+=1\n",
    "        except:\n",
    "            pass\n",
    "    print('Now writing back data')\n",
    "    print('files processed===>'+str(i))\n",
    "    with open(individual_dirs.split('/')[-1]+'.pickle', \"wb\") as f:\n",
    "                pickle.dump(data,f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/noncomm_use_subset.pickle\n",
      "Showing the pickled data:\n",
      "(4678, 8)\n",
      "Null per column\n",
      "paper_id                0\n",
      "title                 289\n",
      "abstract             2901\n",
      "text                  156\n",
      "abstract_tripples       0\n",
      "text_tripples           0\n",
      "key_phrases          4678\n",
      "entities                0\n",
      "dtype: int64\n",
      "/kaggle/working/custom_license.pickle\n",
      "Showing the pickled data:\n",
      "(35238, 8)\n",
      "Null per column\n",
      "paper_id                 0\n",
      "title                 3712\n",
      "abstract             17327\n",
      "text                  1715\n",
      "abstract_tripples        0\n",
      "text_tripples            0\n",
      "key_phrases          35238\n",
      "entities                 0\n",
      "dtype: int64\n",
      "/kaggle/working/biorxiv_medrxiv.pickle\n",
      "Showing the pickled data:\n",
      "(1934, 8)\n",
      "Null per column\n",
      "paper_id                0\n",
      "title                  78\n",
      "abstract              251\n",
      "text                    0\n",
      "abstract_tripples       0\n",
      "text_tripples           0\n",
      "key_phrases          1934\n",
      "entities                0\n",
      "dtype: int64\n",
      "/kaggle/working/comm_use_subset.pickle\n",
      "Showing the pickled data:\n",
      "(18746, 8)\n",
      "Null per column\n",
      "paper_id                 0\n",
      "title                  380\n",
      "abstract             10205\n",
      "text                    71\n",
      "abstract_tripples        0\n",
      "text_tripples            0\n",
      "key_phrases          18746\n",
      "entities                 0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "total_dataframe = pd.DataFrame()\n",
    "models = glob.glob('/kaggle/working/' + \"*.pickle\")\n",
    "#models = glob.glob('/kaggle/working/biorxiv_medrxiv.pickle')\n",
    "# print('models via glob===>'+str(models))\n",
    "for individual_model in models:\n",
    "    print(individual_model)\n",
    "    # open a file, where you stored the pickled data\n",
    "    file = open(individual_model, 'rb')\n",
    "\n",
    "    # dump information to that file\n",
    "    data = pickle.load(file)\n",
    "\n",
    "    # close the file\n",
    "    file.close()\n",
    "\n",
    "    print('Showing the pickled data:')\n",
    "    my_df = pd.DataFrame(data)\n",
    "    print(my_df.shape)\n",
    "    my_df = my_df.replace(r'^\\s*$', np.nan, regex=True)\n",
    "    total_dataframe = total_dataframe.append(my_df, ignore_index=True)\n",
    "    print('Null per column')\n",
    "    print(my_df.isnull().sum())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_dataframe = total_dataframe.drop(['abstract_tripples', 'text_tripples','entities','key_phrases'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total data in dataframe\n",
      "(60596, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_id</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3cdc48bb9e40afd30a59463b7872761a726998c8</td>\n",
       "      <td>experimental evaluation of musca domestica  as...</td>\n",
       "      <td>house ßies  musca domestica l.   were examined...</td>\n",
       "      <td>newcastle disease  is an emerging disease affe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>d99acb4e99be7852aa61a688c9fbd38d44b5a252</td>\n",
       "      <td>evaluation of measles vaccine virus as a vecto...</td>\n",
       "      <td>live attenuated recombinant measles vaccine vi...</td>\n",
       "      <td>live attenuated viruses have been developed an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>748d4c57fe1acc8d9d97cf574f7dea5296f9386c</td>\n",
       "      <td>direct visualization of ebola virus fusion tri...</td>\n",
       "      <td>ebola virus  makes extensive and intricate use...</td>\n",
       "      <td>occurs primarily through a macropinocytosis-li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b891efc6e1419713b05ff7d89b26d260478c28df</td>\n",
       "      <td>NaN</td>\n",
       "      <td>china has the world's second largest tuberculo...</td>\n",
       "      <td>the goal of the present study was to investiga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>353852971069ad5794445e5c1ab6077ce23da75d</td>\n",
       "      <td>comment</td>\n",
       "      <td>NaN</td>\n",
       "      <td>coronavirus disease 2019  has spread with unpr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   paper_id  \\\n",
       "0  3cdc48bb9e40afd30a59463b7872761a726998c8   \n",
       "1  d99acb4e99be7852aa61a688c9fbd38d44b5a252   \n",
       "2  748d4c57fe1acc8d9d97cf574f7dea5296f9386c   \n",
       "3  b891efc6e1419713b05ff7d89b26d260478c28df   \n",
       "4  353852971069ad5794445e5c1ab6077ce23da75d   \n",
       "\n",
       "                                               title  \\\n",
       "0  experimental evaluation of musca domestica  as...   \n",
       "1  evaluation of measles vaccine virus as a vecto...   \n",
       "2  direct visualization of ebola virus fusion tri...   \n",
       "3                                                NaN   \n",
       "4                                            comment   \n",
       "\n",
       "                                            abstract  \\\n",
       "0  house ßies  musca domestica l.   were examined...   \n",
       "1  live attenuated recombinant measles vaccine vi...   \n",
       "2  ebola virus  makes extensive and intricate use...   \n",
       "3  china has the world's second largest tuberculo...   \n",
       "4                                                NaN   \n",
       "\n",
       "                                                text  \n",
       "0  newcastle disease  is an emerging disease affe...  \n",
       "1  live attenuated viruses have been developed an...  \n",
       "2  occurs primarily through a macropinocytosis-li...  \n",
       "3  the goal of the present study was to investiga...  \n",
       "4  coronavirus disease 2019  has spread with unpr...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Total data in dataframe')\n",
    "print(total_dataframe.shape)\n",
    "total_dataframe.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "paper_id        0\n",
       "title        4459\n",
       "abstract    30684\n",
       "text         1942\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_dataframe.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>merged_text</th>\n",
       "      <th>paper_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>experimental evaluation of musca domestica  as...</td>\n",
       "      <td>3cdc48bb9e40afd30a59463b7872761a726998c8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>evaluation of measles vaccine virus as a vecto...</td>\n",
       "      <td>d99acb4e99be7852aa61a688c9fbd38d44b5a252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>direct visualization of ebola virus fusion tri...</td>\n",
       "      <td>748d4c57fe1acc8d9d97cf574f7dea5296f9386c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nanchina has the world's second largest tuberc...</td>\n",
       "      <td>b891efc6e1419713b05ff7d89b26d260478c28df</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>commentnancoronavirus disease 2019  has spread...</td>\n",
       "      <td>353852971069ad5794445e5c1ab6077ce23da75d</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         merged_text  \\\n",
       "0  experimental evaluation of musca domestica  as...   \n",
       "1  evaluation of measles vaccine virus as a vecto...   \n",
       "2  direct visualization of ebola virus fusion tri...   \n",
       "3  nanchina has the world's second largest tuberc...   \n",
       "4  commentnancoronavirus disease 2019  has spread...   \n",
       "\n",
       "                                   paper_id  \n",
       "0  3cdc48bb9e40afd30a59463b7872761a726998c8  \n",
       "1  d99acb4e99be7852aa61a688c9fbd38d44b5a252  \n",
       "2  748d4c57fe1acc8d9d97cf574f7dea5296f9386c  \n",
       "3  b891efc6e1419713b05ff7d89b26d260478c28df  \n",
       "4  353852971069ad5794445e5c1ab6077ce23da75d  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_df = pd.DataFrame()\n",
    "tf_df['merged_text'] = total_dataframe['title'].astype(str) +  total_dataframe['abstract'].astype(str) +  total_dataframe['text'].astype(str)\n",
    "tf_df['paper_id'] = total_dataframe['paper_id']\n",
    "tf_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
